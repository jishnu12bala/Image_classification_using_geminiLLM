{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e55416",
   "metadata": {
    "scrolled": false
   },
  
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install -q -U google-generativeai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e9461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3410cd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\PROJECT\\minor project\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 164.5ms\n",
      "Speed: 0.0ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the objects and their positions in an image:\n",
      "A bus at position Top Right.\n",
      "A person at position Bottom Left.\n",
      "A person at position Bottom Right.\n",
      "A person at position Bottom Left.\n",
      "A person at position Bottom Left.\n",
      "A stop sign at position Top Left.\n",
      "Based on this data, generate a description of the image, considering the spatial relationships between the objects.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # 'n' stands for the Nano model; replace with the appropriate one for your use case\n",
    "\n",
    "# Path to the image file\n",
    "image_path = 'bus.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "height, width, _ = image.shape  # Get the image dimensions\n",
    "\n",
    "# Run the prediction\n",
    "results = model.predict(source=image_path)\n",
    "\n",
    "# Extract the class names and bounding box coordinates\n",
    "class_names = []\n",
    "quadrants = []\n",
    "\n",
    "for pred in results[0].boxes.boxes:\n",
    "    x1, y1, x2, y2, confidence, class_id = pred.tolist()  # Unpack prediction\n",
    "    class_name = model.names[int(class_id)]\n",
    "    class_names.append(class_name)\n",
    "    \n",
    "    # Calculate the center of the bounding box\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "\n",
    "    # Determine the quadrant\n",
    "    if center_x > width / 2 and center_y < height / 2:\n",
    "        quadrant = 'Top Right'\n",
    "    elif center_x > width / 2 and center_y > height / 2:\n",
    "        quadrant = 'Bottom Right'\n",
    "    elif center_x < width / 2 and center_y > height / 2:\n",
    "        quadrant = 'Bottom Left'\n",
    "    else:\n",
    "        quadrant = 'Top Left'\n",
    "    \n",
    "    quadrants.append(quadrant)\n",
    "    \n",
    "    \n",
    "    \n",
    "description_prompt = \"Here are the objects and their positions in an image:\\n\"\n",
    "# Print the class names and their corresponding quadrants\n",
    "for class_name, quadrant in zip(class_names, quadrants):\n",
    "    description_prompt += f\"A {class_name} at position {quadrant}.\\n\"\n",
    "\n",
    "description_prompt += \"Based on this data, generate a description of the image, considering the spatial relationships between the objects.\"\n",
    "    \n",
    "print(description_prompt)"
   ]
  },

   "source": [
    "#setx GEMINI_API_KEY \"your_api_key_here\"<AIzaSyB2DNVe9XYVz1fXFURV5pQX-Kegu5UnGx8>\n",
    "import google.generativeai as genai\n",
    "# Import the Python SDK\n",
    "import google.generativeai as genai\n",
    "# Used to securely store your API key\n",
    "from google.colab import userdata\n",
    "\n",
    "GOOGLE_API_KEY='AIzaSyBgrJYOsr1BHJsoIvt8BPKcayjQ5YqPqUI'\n",
    "genai.configure(api_key=AIzaSyBgrJYOsr1BHJsoIvt8BPKcayjQ5YqPqUI)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
    "print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78919ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('datag', 'images')\n",
    "labels = ['scissor']\n",
    "number_imgs = 10\n",
    "cap = cv2.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(os.path.join(IMAGES_PATH, labels[0]+'.'+str(uuid.uuid1())+'.jpg'))\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        print(imgname)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a16829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from random import choice\n",
    "\n",
    "REV_CLASS_MAP = {\n",
    "    0: \"rock\",\n",
    "    1: \"paper\",\n",
    "    2: \"scissors\",\n",
    "    3: \"none\"\n",
    "}\n",
    "\n",
    "\n",
    "def mapper(val):\n",
    "    return REV_CLASS_MAP[val]\n",
    "\n",
    "\n",
    "def calculate_winner(move1, move2):\n",
    "    if move1 == move2:\n",
    "        return \"Tie\"\n",
    "\n",
    "    if move1 == \"rock\":\n",
    "        if move2 == \"scissors\":\n",
    "            return \"User\"\n",
    "        if move2 == \"paper\":\n",
    "            return \"Computer\"\n",
    "\n",
    "    if move1 == \"paper\":\n",
    "        if move2 == \"rock\":\n",
    "            return \"User\"\n",
    "        if move2 == \"scissors\":\n",
    "            return \"Computer\"\n",
    "\n",
    "    if move1 == \"scissors\":\n",
    "        if move2 == \"paper\":\n",
    "            return \"User\"\n",
    "        if move2 == \"rock\":\n",
    "            return \"Computer\"\n",
    "\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)  \n",
    "cap.set(4, 720)  \n",
    "\n",
    "prev_move = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    cv2.rectangle(frame, (100, 100), (500, 500), (255, 255, 255), 2)\n",
    "   \n",
    "    cv2.rectangle(frame, (800, 100), (1200, 500), (255, 255, 255), 2)\n",
    "\n",
    "    \n",
    "    img = frame[100:500, 100:500]\n",
    "    img = cv2.resize(img, (227, 227))\n",
    "\n",
    "  \n",
    "    pred = model.predict(frame)\n",
    "    results = model(frame)\n",
    "    move_code=0\n",
    "    names = model.names\n",
    "\n",
    "    for r in results:\n",
    "        for c in r.boxes.cls:\n",
    "            pred_name=names[int(c)]\n",
    "            if pred_name==\"stone\":\n",
    "                move_code=0\n",
    "            elif pred_name==\"paper\":\n",
    "                move_code=1\n",
    "            elif pred_name==\"scissor\":\n",
    "                move_code=2\n",
    "            else:\n",
    "                move_code=3\n",
    "            \n",
    "    user_move_name = mapper(move_code)\n",
    "    \n",
    "\n",
    "    if prev_move != user_move_name:\n",
    "        if user_move_name != \"none\":\n",
    "            computer_move_name = choice(['rock', 'paper', 'scissors'])\n",
    "            winner = calculate_winner(user_move_name, computer_move_name)\n",
    "        else:\n",
    "            computer_move_name = \"none\"\n",
    "            winner = \"Waiting...\"\n",
    "    prev_move = user_move_name\n",
    "\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, \"Your Move: \" + user_move_name,(50, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Computer's Move: \" + computer_move_name,(750, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"Winner: \" + winner,(400, 600), font, 2, (0, 0, 255), 4, cv2.LINE_AA)\n",
    "\n",
    "    if computer_move_name != \"none\":\n",
    "        icon = cv2.imread(\"images/{}.png\".format(computer_move_name))\n",
    "        icon = cv2.resize(icon, (400, 400))\n",
    "        frame[100:500, 800:1200] = icon\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"Rock Paper Scissors\", frame)\n",
    "\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
